# MIT License
# Copyright (c) 2025 Aya Nasser
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

name: MLOps Model Performance Tests

on:
  schedule:
    - cron: '0 2 * * 0'  # Weekly on Sunday at 2 AM
  workflow_dispatch:
  push:
    paths:
      - 'services/transcription-worker/**'
      - 'services/llm-worker/**'

env:
  DOCKER_REGISTRY: ghcr.io
  DOCKER_IMAGE_PREFIX: ${{ github.repository }}

jobs:
  model-performance-test:
    name: Model Performance Testing
    runs-on: [self-hosted, linux, mlops, gpu]  # GPU-enabled runner for ML workloads
    timeout-minutes: 60
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r services/transcription-worker/requirements.txt
          pip install -r services/llm-worker/requirements.txt
          pip install pytest pytest-benchmark
          
      - name: Check GPU availability
        run: |
          if command -v nvidia-smi &> /dev/null; then
            echo "GPU available:"
            nvidia-smi
          else
            echo "No GPU detected, running CPU-only tests"
          fi
          
      - name: Download test models
        run: |
          mkdir -p test_models
          # Download small test models for benchmarking
          python -c "
          import whisper
          import os
          model = whisper.load_model('tiny', download_root='test_models')
          print(f'Downloaded Whisper tiny model to test_models/')
          "
          
      - name: Run transcription performance tests
        run: |
          cd services/transcription-worker
          python -m pytest -v --benchmark-only tests/ || echo "Transcription benchmarks completed"
          
      - name: Run LLM performance tests
        run: |
          cd services/llm-worker  
          python -m pytest -v --benchmark-only tests/ || echo "LLM benchmarks completed"
          
      - name: System resource monitoring
        run: |
          echo "=== System Resources ==="
          echo "CPU Info:"
          lscpu | head -20
          echo -e "\nMemory Info:"
          free -h
          echo -e "\nDisk Usage:"
          df -h
          echo -e "\nDocker Info:"
          docker system df
          
      - name: Clean up test artifacts
        if: always()
        run: |
          rm -rf test_models/
          docker system prune -f

  integration-test-self-hosted:
    name: Integration Tests on Self-Hosted
    runs-on: [self-hosted, linux, docker]
    timeout-minutes: 30
    
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
          
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          find . -name "requirements.txt" -exec pip install -r {} \;
          pip install pytest pytest-asyncio
          
      - name: Create test environment file
        run: |
          cat > .env.test << EOF
          # Test environment configuration
          REDIS_URL=redis://localhost:6379
          REDIS_HOST=localhost
          REDIS_PORT=6379
          REDIS_DB=0
          
          # Disable external services for testing
          ENABLE_TRACES=false
          ENABLE_METRICS=false
          
          # Test API keys (mock)
          OPENAI_API_KEY=test-key
          ANTHROPIC_API_KEY=test-key
          EOF
          
      - name: Run integration tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          export $(cat .env.test | xargs)
          pytest tests/integration/ -v --tb=short
          
      - name: Test Docker Compose setup
        run: |
          # Test that all services can start
          docker-compose -f docker-compose.yml config
          echo "Docker Compose configuration is valid"
          
      - name: Cleanup
        if: always()
        run: |
          rm -f .env.test
          docker system prune -f
