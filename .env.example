# Application Configuration
APP_NAME="Transcription Pipeline"
DEBUG=false
ENVIRONMENT=development
BUILD_TARGET=development

# OpenAI Configuration (Required)
OPENAI_API_KEY="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"

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Database Configuration
DATABASE_URL=postgresql://user:password@postgres:5432/transcription_db

# Storage Configuration
STORAGE_TYPE=local
STORAGE_LOCAL_PATH=/app/storage
STORAGE_GCS_BUCKET=
STORAGE_GCS_CREDENTIALS_PATH=

# Whisper Configuration
WHISPER_CACHE_DIR=/app/whisper_cache
WHISPER_DEVICE=cpu

# Rate Limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_REQUESTS_PER_HOUR=1000

# Monitoring
MONITORING_PROMETHEUS_PORT=8080
MONITORING_LOG_LEVEL=INFO

# Worker Configuration
MAX_CONCURRENT_JOBS=4
JOB_TIMEOUT_SECONDS=3600

# File Validation
MAX_FILE_SIZE_MB=500

# OpenAI Settings
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.2

# Alternative LLM Providers (Optional)
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-haiku-20240307
ANTHROPIC_MAX_TOKENS=1024
ANTHROPIC_TEMPERATURE=0.2

MISTRAL_API_KEY=
MISTRAL_MODEL=mistral-large-latest
MISTRAL_MAX_TOKENS=1000
MISTRAL_TEMPERATURE=0.2

# Local LLM Fallback (Optional)
LOCAL_LLM_ENABLED=false
LOCAL_LLM_MODEL=llama-3-8b-instruct
LOCAL_LLM_ENDPOINT=http://localhost:8080/v1

# Observability Configuration
OBSERVABILITY_OTLP_ENDPOINT=http://otel-collector:4317
OBSERVABILITY_OTLP_INSECURE=true
OBSERVABILITY_ENABLE_TRACES=true
OBSERVABILITY_ENABLE_METRICS=true
OBSERVABILITY_SAMPLE_RATE=1.0

# GCP Configuration (Optional - for cloud deployment)
GOOGLE_CLOUD_PROJECT=
GOOGLE_APPLICATION_CREDENTIALS=
GCS_BUCKET_NAME=
PUBSUB_TOPIC_TRANSCRIPTION=
PUBSUB_TOPIC_LLM=
